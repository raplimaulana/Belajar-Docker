### DOCKER SWARM ###
A swarm is a cluster of one or more computers running Docker. 
It can consist of one or more machines, so you can use swarm functionality on your local machine.

With the introduction of swarm mode, Docker received built-in orchestration, clustering and scheduling capabilities. 
Features for handling multiple machines, like health checks, load balancing and a bunch of other nice things are now included out-of-the-box.

When you run containers with the Docker command, swarm mode does not come into play by default. 
If you are using swarm mode, you are dealing on a higher abstraction level - services instead of containers. You can deal with both kinds on the same machine.

When a container is running in service mode, swarm mode takes over and manages the lifecycle of the service. 
It strives to bring up a desired number of replicas, as specified in the definition. That part of the funcionality is very similar to Kubernetes.
The activities of the cluster are controlled by a swarm manager, and machines that have joined the cluster are referred to as nodes. 

Feature Docker Swarm
•	Cluster management integrated with Docker Engine: 
    Use the Docker Engine CLI to create a swarm of Docker Engines where you can deploy application services. 
    You don’t need additional orchestration software to create or manage a swarm.

•	Decentralized design: 
    Instead of handling differentiation between node roles at deployment time, the Docker Engine handles any specialization at runtime. 
    You can deploy both kinds of nodes, managers and workers, using the Docker Engine. 
    This means you can build an entire swarm from a single disk image.

•	Declarative service model: 
    Docker Engine uses a declarative approach to let you define the desired state of the various services in your application stack. 
    For example, you might describe an application comprised of a web front end service with message queueing services and a database backend.

•	Scaling: 
    For each service, you can declare the number of tasks you want to run. 
    When you scale up or down, the swarm manager automatically adapts by adding or removing tasks to maintain the desired state.

•	Desired state reconciliation: 
    The swarm manager node constantly monitors the cluster state and reconciles any differences between the actual state and your expressed desired state. 
    For example, if you set up a service to run 10 replicas of a container, and a worker machine hosting two of those replicas crashes, the manager creates two new replicas to replace the replicas that crashed. The swarm manager assigns the new replicas to workers that are running and available.

•	Multi-host networking: 
    You can specify an overlay network for your services. 
    The swarm manager automatically assigns addresses to the containers on the overlay network when it initializes or updates the application.

•	Service discovery: 
    Swarm manager nodes assign each service in the swarm a unique DNS name and load balances running containers. 
    You can query every container running in the swarm through a DNS server embedded in the swarm.

•	Load balancing: 
    You can expose the ports for services to an external load balancer. 
    Internally, the swarm lets you specify how to distribute service containers between nodes.

•	Secure by default: 
    Each node in the swarm enforces TLS mutual authentication and encryption to secure communications between itself and all other nodes. 
    You have the option to use self-signed root certificates or certificates from a custom root CA.

•	Rolling updates: 
    At rollout time you can apply service updates to nodes incrementally. The swarm manager lets you control the delay between service deployment to different sets of nodes. 
    If anything goes wrong, you can roll back to a previous version of the service.
 

##create Swarm
1. Initialization Docker Swarm                                #Execute in pod-raplima-node01 (10.10.10.10)
   docker swarm init --advertise-addr 10.10.10.10

2. Copy command docker join                                   #Execute in pod-raplima-node02 (10.10.10.20)
   docker swarm join --token [TOKEN] 10.10.10.10:2377

3. Check if node02 already join                               #Execute in pod-raplima-node01 (10.10.10.10)
   docker node ls


##deploy service to Swarm                                     #Execute in pod-raplima-node01 (10.10.10.10)
1. Create service Nginx with 2 replica
   docker service create --name web --replicas 2 -p 80:80 training.btech.id/btacademy/nginx:latest

2. Check service running correctly in all node
   docker service ls

3. Test Browsing From node01 and node02
   curl http://10.10.10.10
   curl http://10.10.10.20
   
   *If the configuration is correct there will show nginx default page from node01 and node02

4. Check information about the service
   docker service inspect --pretty web

5. If we want to check where the service is running
   docker service ps web

6. Create container with limit cpu and limit memory
   docker service create --name raplicontainer --reserve-cpu 1 --limit-cpu 1 --reserve-memory  256mb --limit-memory 128mb httpd:latest


##Docker Swarm scale & update                                 #Execute in pod-raplima-node01 (10.10.10.10)
1. Create service Nginx with 3 replica
   docker service create --name web2 --replicas 3 -p 80:80 training.btech.id/btacademy/nginx:latest

2. We can change the replica of the service
   docker service scale web2=1

3. Check if replica already change
   docker service ls
   docker service ps web2

4. Docker Swarm can rolling update the service
   docker service update --image sistyo/myweb web2

5. Check information about the service
   docker service inspect --pretty web2
